# üíæ **Base de Datos del Sistema**

## üéØ **Prop√≥sito de esta Carpeta**

Esta carpeta contiene **TODO lo relacionado con la base de datos persistente** del sistema:

- **Esquema SQL** (`schema.sql`) - Estructura de tablas optimizada para series temporales
- **Base de datos SQLite** (`semaforos.db`) - Para desarrollo local
- **Migraciones** (`migraciones/`) - Versionamiento del esquema con Alembic

---

## üóÑÔ∏è **Relaci√≥n con Otras Carpetas**

```
base-datos/  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Persistencia estructurada (SQL)
    ‚îÇ
    ‚îú‚îÄ ESCRIBE ‚Üê servidor-backend/servicios/
    ‚îÇ            (m√©tricas en tiempo real)
    ‚îÇ
    ‚îú‚îÄ ESCRIBE ‚Üê integracion-sumo/conector_sumo.py
    ‚îÇ            (exportaci√≥n SUMO)
    ‚îÇ
    ‚îú‚îÄ LEE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí servidor-backend/rutas/estadisticas.py
    ‚îÇ            (consultas hist√≥ricas)
    ‚îÇ
    ‚îî‚îÄ LEE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Calculo-Matlab/*.m
                 (an√°lisis offline)

datos/  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Archivos temporales (CSV, Parquet, logs)
```

### **¬øCu√°ndo usar `base-datos/` vs `datos/`?**

| Tipo de Dato | D√≥nde | Ejemplo |
|--------------|-------|---------|
| **Series temporales estructuradas** | `base-datos/` (SQL) | M√©tricas de tr√°fico cada segundo |
| **Archivos temporales** | `datos/` | CSV de an√°lisis de video |
| **Resultados de procesamiento** | `datos/` | Frames anotados de YOLO |
| **Modelos ML entrenados** | `datos/` | `predictor_icv_v1.pkl` |
| **Historial de emergencias** | `base-datos/` (SQL) | Olas verdes activadas |
| **Logs del sistema** | `datos/` | `backend-2025-01-15.log` |

---

## üìä **Esquema de Base de Datos**

Ver **`schema.sql`** para el esquema completo.

### **Tablas Principales:**

1. **`intersecciones`** - Cat√°logo de las 31 intersecciones de Lima
2. **`metricas_trafico`** - Series temporales (TimescaleDB hypertable)
3. **`olas_verdes`** - Historial de veh√≠culos de emergencia
4. **`detecciones_video`** - Detecciones YOLO individuales
5. **`simulaciones_sumo`** - Datos exportados desde SUMO
6. **`decisiones_difusas`** - Log del controlador difuso
7. **`conexiones_intersecciones`** - Grafo de red vial

---

## üöÄ **Configuraci√≥n**

### **Desarrollo (SQLite)**

SQLite se usa autom√°ticamente en desarrollo:

```python
# En servidor-backend/config.py
DATABASE_URL = "sqlite:///./base-datos/semaforos.db"
```

### **Producci√≥n (PostgreSQL + TimescaleDB)**

Para producci√≥n, cambiar a TimescaleDB:

```python
# En servidor-backend/config.py
DATABASE_URL = "postgresql://user:pass@localhost:5432/semaforos"
```

**Instalar TimescaleDB:**

```bash
# PostgreSQL con TimescaleDB
docker run -d --name timescaledb \
  -p 5432:5432 \
  -e POSTGRES_PASSWORD=password \
  timescale/timescaledb:latest-pg15

# Crear base de datos
psql -U postgres -h localhost
CREATE DATABASE semaforos;
\c semaforos
CREATE EXTENSION IF NOT EXISTS timescaledb;

# Ejecutar schema.sql
psql -U postgres -h localhost -d semaforos -f schema.sql
```

---

## üîß **Uso desde Python**

### **1. Insertar M√©tricas en Tiempo Real**

```python
from servicios.estadisticas_service import EstadisticasService

# Guardar m√©tricas
EstadisticasService.guardar_metricas(
    interseccion_id='LC-001',
    timestamp=datetime.now(),
    num_vehiculos=45,
    icv=0.65,
    flujo=120.5,
    velocidad=35.2,
    longitud_cola=78.5,
    fuente='simulador'
)
```

### **2. Consultar Datos Hist√≥ricos**

```python
# Obtener m√©tricas de las √∫ltimas 24 horas
metricas = EstadisticasService.obtener_metricas_periodo(
    interseccion_id='LC-001',
    horas=24
)

# Calcular estad√≠sticas agregadas
stats = EstadisticasService.calcular_estadisticas(
    interseccion_id='LC-001',
    periodo_inicio=datetime(2025, 1, 1),
    periodo_fin=datetime(2025, 1, 31)
)

print(f"ICV Promedio: {stats['icv_promedio']}")
print(f"Horas de congesti√≥n: {stats['horas_congestion']}")
```

### **3. Exportar para Machine Learning**

```python
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('sqlite:///./base-datos/semaforos.db')

# Extraer datos de entrenamiento
query = """
SELECT timestamp, interseccion_id, icv, flujo_vehicular,
       velocidad_promedio, longitud_cola
FROM metricas_trafico
WHERE timestamp >= datetime('now', '-30 days')
"""

df = pd.read_sql(query, engine)

# Entrenar modelo
from sklearn.ensemble import RandomForestRegressor
X = df[['flujo_vehicular', 'velocidad_promedio', 'longitud_cola']]
y = df['icv']

modelo = RandomForestRegressor()
modelo.fit(X, y)

# Guardar
import joblib
joblib.dump(modelo, 'datos/modelos-entrenados/predictor_icv_v2.pkl')
```

---

## üìà **Migraciones (Alembic)**

### **Inicializar Alembic**

```bash
cd servidor-backend
pip install alembic
alembic init ../base-datos/migraciones
```

### **Crear Nueva Migraci√≥n**

```bash
alembic revision -m "Agregar columna metadata a intersecciones"
```

### **Aplicar Migraciones**

```bash
alembic upgrade head
```

### **Revertir Migraci√≥n**

```bash
alembic downgrade -1
```

---

## üîç **Consultas √ötiles**

### **ICV Promedio por Zona**

```sql
SELECT i.zona, AVG(mt.icv) as icv_promedio
FROM metricas_trafico mt
INNER JOIN intersecciones i ON mt.interseccion_id = i.id
WHERE mt.timestamp >= NOW() - INTERVAL '24 hours'
GROUP BY i.zona
ORDER BY icv_promedio DESC;
```

### **Intersecciones M√°s Congestionadas**

```sql
SELECT interseccion_id, AVG(icv) as icv_promedio
FROM metricas_trafico
WHERE timestamp >= NOW() - INTERVAL '7 days'
GROUP BY interseccion_id
ORDER BY icv_promedio DESC
LIMIT 10;
```

### **Olas Verdes Activas**

```sql
SELECT * FROM olas_verdes_activas;  -- Vista
```

### **Estad√≠sticas de Emergencias**

```sql
SELECT tipo_vehiculo, COUNT(*) as total,
       AVG(tiempo_total_segundos) as tiempo_promedio
FROM olas_verdes
WHERE completado = TRUE
GROUP BY tipo_vehiculo;
```

---

## üß™ **Testing**

```python
# tests/test_database.py
import pytest
from sqlalchemy import create_engine
from datetime import datetime

def test_insertar_metrica():
    engine = create_engine('sqlite:///:memory:')
    # ... crear tablas con schema.sql

    # Insertar m√©trica
    conn = engine.connect()
    conn.execute("""
        INSERT INTO metricas_trafico
        (timestamp, interseccion_id, icv, fuente)
        VALUES (?, ?, ?, ?)
    """, (datetime.now(), 'LC-001', 0.65, 'test'))

    # Verificar
    result = conn.execute(
        "SELECT COUNT(*) FROM metricas_trafico"
    ).scalar()

    assert result == 1
```

---

## üìö **Recursos**

- **PostgreSQL**: https://www.postgresql.org/docs/
- **TimescaleDB**: https://docs.timescale.com/
- **Alembic**: https://alembic.sqlalchemy.org/
- **SQLAlchemy**: https://docs.sqlalchemy.org/

---

## üîê **Seguridad**

### **Desarrollo**

```python
# ‚úÖ OK para desarrollo
DATABASE_URL = "sqlite:///./base-datos/semaforos.db"
```

### **Producci√≥n**

```python
# ‚ùå MAL - Nunca hardcodear credenciales
DATABASE_URL = "postgresql://admin:1234@localhost/semaforos"

# ‚úÖ BIEN - Usar variables de entorno
import os
DATABASE_URL = os.getenv('DATABASE_URL')
```

**.env:**
```
DATABASE_URL=postgresql://admin:password@localhost:5432/semaforos
```

---

## üìä **Monitoreo**

### **Tama√±o de la Base de Datos**

```sql
-- PostgreSQL
SELECT pg_size_pretty(pg_database_size('semaforos'));

-- SQLite
SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size();
```

### **Tablas M√°s Grandes**

```sql
-- PostgreSQL
SELECT schemaname, tablename,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

---

## üéØ **Roadmap**

- [ ] Implementar SQLAlchemy ORM en `servidor-backend/modelos_bd/`
- [ ] Crear script `poblar_intersecciones.py`
- [ ] Configurar Alembic para migraciones
- [ ] Implementar exportaci√≥n autom√°tica SUMO ‚Üí BD
- [ ] Agregar √≠ndices adicionales para consultas ML
- [ ] Configurar backup autom√°tico
- [ ] Implementar pol√≠tica de retenci√≥n (1 a√±o)
- [ ] Agregar m√©tricas de monitoreo (Prometheus)

---

**üîó Ver tambi√©n:** `ARQUITECTURA_COMPLETA.md` en la ra√≠z del proyecto
