# üé• M√≥dulo de Visi√≥n Computacional - 100% REAL

## üéØ Prop√≥sito

Este m√≥dulo procesa videos reales de intersecciones vehiculares para extraer m√©tricas de tr√°fico usando:

- ‚úÖ **YOLOv8** para detecci√≥n de veh√≠culos
- ‚úÖ **Tracking real** (DeepSORT) para calcular velocidad
- ‚úÖ **Modelo custom** para veh√≠culos de emergencia
- ‚úÖ **C√°lculo ICV real** usando `nucleo/indice_congestion.py`
- ‚úÖ **Exportaci√≥n a Azure** Blob Storage

‚ö†Ô∏è **IMPORTANTE**: Este m√≥dulo **NO USA `np.random`** - Todas las m√©tricas son REALES basadas en detecciones y c√°lculos verificables.

---

## üìÅ Estructura del M√≥dulo

```
vision_computadora/
‚îú‚îÄ‚îÄ procesador_video.py         # Procesador principal (100% real, sin random)
‚îú‚îÄ‚îÄ procesador_modular.py       # Sistema modular con 3 modos de evaluaci√≥n
‚îú‚îÄ‚îÄ tracking_vehicular.py       # Tracking real para velocidad (DeepSORT/Centroid)
‚îú‚îÄ‚îÄ detector_emergencia.py      # Detector custom de ambulancias/bomberos/polic√≠a
‚îú‚îÄ‚îÄ exportador_azure.py         # Exportador a Azure Blob Storage
‚îú‚îÄ‚îÄ test_yolo_fix.py            # Tests de YOLO
‚îú‚îÄ‚îÄ test_yolo_visual.py         # Visualizaci√≥n de YOLO
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

---

## üöÄ Instalaci√≥n

### **Dependencias B√°sicas**

```bash
pip install ultralytics opencv-python numpy
```

### **Tracking Robusto (Recomendado)**

```bash
pip install deep-sort-realtime
```

### **Exportaci√≥n a Azure (Opcional)**

```bash
pip install azure-storage-blob python-dotenv
```

### **Gr√°ficos (Opcional)**

```bash
pip install matplotlib
```

---

## üîß Uso R√°pido

### **1. Procesamiento B√°sico**

```bash
python vision_computadora/procesador_video.py datos/videos-prueba/analisis-parametros/test_congestion.mp4
```

### **2. Procesamiento Modular (Recomendado)**

#### **Modo 1: Detecci√≥n B√°sica**
Solo detecta veh√≠culos con bounding boxes.

```bash
python vision_computadora/procesador_modular.py \
    --modo deteccion \
    --video datos/videos-prueba/deteccion-basica/test_deteccion_dia.mp4 \
    --visualizar \
    --exportar
```

**Outputs**:
- Video procesado con bounding boxes
- CSV con detecciones por frame
- JSON con estad√≠sticas

#### **Modo 2: An√°lisis de Par√°metros**
Calcula velocidad, flujo, ICV, longitud de cola.

```bash
python vision_computadora/procesador_modular.py \
    --modo parametros \
    --video datos/videos-prueba/analisis-parametros/test_congestion.mp4 \
    --visualizar \
    --exportar
```

**Outputs**:
- Video procesado con m√©tricas superpuestas
- CSV con m√©tricas por frame (velocidad REAL, ICV REAL)
- Gr√°fico de ICV vs tiempo
- JSON con estad√≠sticas

#### **Modo 3: Detecci√≥n de Emergencia**
Detecta veh√≠culos de emergencia (requiere modelo custom entrenado).

```bash
python vision_computadora/procesador_modular.py \
    --modo emergencia \
    --video datos/videos-prueba/deteccion-emergencia/test_ambulancia.mp4 \
    --visualizar \
    --exportar
```

**Outputs**:
- Video procesado con alertas de emergencia
- CSV con detecciones de emergencia
- JSON con estad√≠sticas por tipo

---

## üìä Outputs Generados

### **Estructura de Archivos de Salida**

```
datos/resultados-video/exportaciones/
‚îú‚îÄ‚îÄ deteccion/
‚îÇ   ‚îú‚îÄ‚îÄ video_name_deteccion.mp4
‚îÇ   ‚îú‚îÄ‚îÄ video_name_detecciones.csv
‚îÇ   ‚îî‚îÄ‚îÄ video_name_stats.json
‚îÇ
‚îú‚îÄ‚îÄ parametros/
‚îÇ   ‚îú‚îÄ‚îÄ video_name_parametros.mp4
‚îÇ   ‚îú‚îÄ‚îÄ video_name_metricas.csv
‚îÇ   ‚îú‚îÄ‚îÄ video_name_icv_graph.png
‚îÇ   ‚îî‚îÄ‚îÄ video_name_stats.json
‚îÇ
‚îî‚îÄ‚îÄ emergencia/
    ‚îú‚îÄ‚îÄ video_name_emergencia.mp4
    ‚îú‚îÄ‚îÄ video_name_emergencias.csv
    ‚îî‚îÄ‚îÄ video_name_stats.json
```

### **Ejemplo de CSV de M√©tricas (Modo Par√°metros)**

```csv
Frame,Tiempo(s),NumVehiculos,Flujo(veh/min)_REAL,Velocidad(km/h)_REAL,LongitudCola(m),ICV_REAL,Clasificacion,Emergencia
0,0.00,12,72.00,35.20,78.50,0.485,moderado,No
30,1.00,15,90.00,28.50,95.30,0.610,congestionado,No
60,2.00,8,48.00,45.10,42.00,0.285,fluido,No
```

‚ö†Ô∏è **Nota**: Todos los valores son **REALES**, no simulados.

---

## üî¨ M√≥dulos Internos

### **1. `procesador_video.py` - Procesador Principal**

Clase principal para procesar videos.

```python
from vision_computadora.procesador_video import ProcesadorVideo

# Crear procesador
procesador = ProcesadorVideo(
    ruta_video="mi_video.mp4",
    pixeles_por_metro=15.0  # Ajustar seg√∫n calibraci√≥n
)

# Procesar video completo
resultados = procesador.procesar_completo(saltar_frames=2)

# Exportar resultados
procesador.exportar_resultados(resultados, "resultados.csv")

# Estad√≠sticas
for r in resultados:
    print(f"Frame {r.numero_frame}:")
    print(f"  Velocidad: {r.velocidad_promedio:.1f} km/h [REAL]")
    print(f"  ICV: {r.icv:.3f} [REAL - nucleo/]")
```

**Caracter√≠sticas**:
- ‚ùå **NO USA `np.random`**
- ‚úÖ Velocidad calculada con tracking real
- ‚úÖ ICV calculado con `nucleo/indice_congestion.py`
- ‚úÖ Detecci√≥n de emergencias con modelo custom

---

### **2. `tracking_vehicular.py` - Tracking Real**

Calcula velocidad REAL basada en movimiento observado.

```python
from vision_computadora.tracking_vehicular import TrackerVehicular

# Crear tracker
tracker = TrackerVehicular(
    fps=30.0,
    pixeles_por_metro=15.0,
    usar_deepsort=True  # Usar DeepSORT si est√° disponible
)

# Actualizar con detecciones
vehiculos_trackeados = tracker.actualizar(detecciones, timestamp)

# Obtener velocidad promedio REAL
velocidad = tracker.obtener_velocidad_promedio_general()
print(f"Velocidad promedio: {velocidad:.1f} km/h [REAL - Tracking]")
```

**M√©todos de Tracking**:
1. **DeepSORT** (recomendado si disponible): Tracking robusto con re-identificaci√≥n
2. **Centroid Tracking** (fallback): Tracking simple basado en distancia entre centroides

‚ö†Ô∏è **Ambos calculan velocidad REAL** - No hay `np.random` en ninguna parte.

---

### **3. `detector_emergencia.py` - Veh√≠culos de Emergencia**

Detecta ambulancias, bomberos y polic√≠a con modelo YOLOv8 custom.

```python
from vision_computadora.detector_emergencia import DetectorEmergencia

# Crear detector
detector = DetectorEmergencia()

if detector.modelo_disponible:
    # Detectar en frame
    detecciones = detector.detectar(frame, frame_num)

    for det in detecciones:
        print(f"{det.tipo.upper()} detectado: {det.confianza:.2f}")
```

**Entrenamiento del Modelo**:
Ver: `datos/entrenamiento-emergencia/README.md`

---

### **4. `exportador_azure.py` - Exportaci√≥n a Cloud**

Exporta resultados a Azure Blob Storage.

```python
from vision_computadora.exportador_azure import ExportadorAzure

# Crear exportador
exportador = ExportadorAzure()

# Subir archivo
url = exportador.subir_archivo("resultado.mp4")
print(f"Subido: {url}")

# Subir directorio completo
urls = exportador.subir_directorio("datos/resultados-video/exportaciones/parametros/")
```

**Configuraci√≥n** (archivo `.env`):
```
AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net
AZURE_STORAGE_CONTAINER_NAME=trafico-lima
```

---

## üéØ Modos de Procesamiento Modular

### **Modo 1: Detecci√≥n B√°sica** üìπ

**Prop√≥sito**: Validar que YOLO detecta veh√≠culos correctamente.

**Qu√© hace**:
- Detecta veh√≠culos con YOLO
- Dibuja bounding boxes
- Muestra confianza

**Qu√© NO hace**:
- NO calcula velocidad (eso es modo 2)
- NO calcula ICV (eso es modo 2)
- NO detecta emergencias (eso es modo 3)

**Cu√°ndo usar**:
- Para validar precisi√≥n de YOLO
- Para evaluar rendimiento (FPS)
- Para verificar detecci√≥n en diferentes condiciones (d√≠a/noche/lluvia)

---

### **Modo 2: An√°lisis de Par√°metros** üìä

**Prop√≥sito**: Validar que se calculan m√©tricas de tr√°fico REALES.

**Qu√© hace**:
- Detecta veh√≠culos
- **Trackea** veh√≠culos entre frames
- Calcula **velocidad REAL** usando tracking
- Calcula **flujo vehicular**
- Mide **longitud de cola**
- Calcula **ICV REAL** usando `nucleo/indice_congestion.py`

**Cu√°ndo usar**:
- Para validar que velocidad NO es random
- Para verificar que ICV es real
- Para generar datos para tesis
- Para comparar con datos de SUMO

---

### **Modo 3: Detecci√≥n de Emergencia** üö®

**Prop√≥sito**: Validar detecci√≥n de veh√≠culos de emergencia.

**Qu√© hace**:
- Detecta veh√≠culos est√°ndar
- Detecta veh√≠culos de emergencia (modelo custom)
- Resalta emergencias en color especial
- Emite alertas visuales

**Requisito**:
- Modelo custom entrenado (ver `datos/entrenamiento-emergencia/README.md`)

**Cu√°ndo usar**:
- Para validar modelo custom
- Para testear integraci√≥n con olas verdes
- Para demos en presentaciones

---

## üìê Calibraci√≥n Espacial

Para calcular velocidad REAL, necesitas calibrar `pixeles_por_metro`.

### **M√©todo Manual**

1. Medir distancia conocida en el video (e.g., longitud de veh√≠culo = 4.5m)
2. Medir la misma distancia en p√≠xeles en el frame
3. Calcular: `pixeles_por_metro = pixeles / metros`

**Ejemplo**:
- Un veh√≠culo de 4.5m ocupa 68 p√≠xeles
- `pixeles_por_metro = 68 / 4.5 ‚âà 15.1`

### **Valores T√≠picos**

| √Ångulo de C√°mara | Pixeles/Metro Aprox. |
|-------------------|----------------------|
| Cenital (desde arriba) | 20-30 |
| Oblicuo (45¬∞) | 10-20 |
| Lateral | 5-15 |

‚ö†Ô∏è **Importante**: La calibraci√≥n afecta la precisi√≥n de velocidad. Ajustar seg√∫n tu video.

---

## üß™ Testing

### **Test de YOLO**

```bash
python vision_computadora/test_yolo_visual.py
```

Abre webcam y muestra detecciones en tiempo real.

### **Test de Tracking**

```python
from vision_computadora.tracking_vehicular import TrackerVehicular

tracker = TrackerVehicular()

# Simular 3 frames con movimiento
detecciones_t0 = [{'bbox': [100, 200, 150, 250], 'clase': 2, 'confianza': 0.9}]
detecciones_t1 = [{'bbox': [105, 200, 155, 250], 'clase': 2, 'confianza': 0.9}]
detecciones_t2 = [{'bbox': [110, 200, 160, 250], 'clase': 2, 'confianza': 0.9}]

tracker.actualizar(detecciones_t0, 0.0)
tracker.actualizar(detecciones_t1, 0.033)
vehiculos = tracker.actualizar(detecciones_t2, 0.066)

for v in vehiculos:
    print(f"Velocidad: {v.velocidad_promedio:.2f} km/h [REAL]")
```

---

## üìö Ejemplos de Uso

### **Ejemplo 1: Procesar Video y Exportar a Azure**

```python
from vision_computadora.procesador_modular import ProcesadorModular
from vision_computadora.exportador_azure import exportar_resultados_a_azure

# Procesar
procesador = ProcesadorModular(
    ruta_video="test_trafico.mp4",
    modo="parametros"
)

stats = procesador.procesar(
    visualizar=False,
    exportar_datos=True,
    directorio_salida="datos/resultados-video/exportaciones/parametros/"
)

# Subir a Azure
exportar_resultados_a_azure(
    "datos/resultados-video/exportaciones/parametros/",
    modo="parametros"
)
```

### **Ejemplo 2: Procesar con Callback Personalizado**

```python
from vision_computadora.procesador_video import ProcesadorVideo

procesador = ProcesadorVideo("video.mp4")

for frame_num in range(0, procesador.total_frames, 10):
    ret, frame = procesador.video.read()
    if not ret:
        break

    resultado = procesador.procesar_frame(frame, frame_num)

    # Callback personalizado
    if resultado.icv > 0.7:
        print(f"‚ö†Ô∏è CONGESTI√ìN ALTA en frame {frame_num}: ICV={resultado.icv:.3f}")

    if resultado.hay_emergencia:
        print(f"üö® EMERGENCIA detectada en frame {frame_num}")
```

---

## üéì Integraci√≥n con Otros M√≥dulos

### **Integraci√≥n con `nucleo/`**

```python
# El procesador usa nucleo/ internamente
resultado_icv = procesador.calculador_icv.calcular(
    longitud_cola=80.5,
    velocidad_promedio=32.1,
    flujo_vehicular=125.0
)

print(f"ICV: {resultado_icv['icv']:.3f}")
print(f"Clasificaci√≥n: {resultado_icv['clasificacion']}")
```

### **Integraci√≥n con `servidor-backend/`**

```python
# En servidor-backend/servicios/video_service.py
from vision_computadora.procesador_video import ProcesadorVideo

async def procesar_video_endpoint(video_id: str):
    procesador = ProcesadorVideo(f"datos/videos/{video_id}.mp4")
    resultados = procesador.procesar_completo()

    # Guardar en base de datos
    for r in resultados:
        await guardar_metricas_bd(
            timestamp=r.timestamp,
            icv=r.icv,
            velocidad=r.velocidad_promedio,
            fuente='video'
        )
```

---

## ‚ö†Ô∏è Limitaciones y Consideraciones

1. **Calibraci√≥n**: La precisi√≥n de velocidad depende de `pixeles_por_metro`
2. **√Ångulo de C√°mara**: Perspectivas muy oblicuas reducen precisi√≥n
3. **Oclusiones**: Veh√≠culos ocultos pueden perder tracking
4. **Condiciones Clim√°ticas**: Lluvia intensa puede afectar detecci√≥n
5. **Modelo de Emergencia**: Requiere entrenamiento con dataset de veh√≠culos peruanos

---

## üîÑ Roadmap

- [x] Eliminar todo `np.random` (velocidad, ICV, emergencias)
- [x] Integrar tracking real (DeepSORT)
- [x] Integrar `nucleo/indice_congestion.py`
- [x] Crear sistema modular de evaluaci√≥n
- [x] Exportaci√≥n a Azure Blob Storage
- [ ] Calibraci√≥n autom√°tica de perspectiva
- [ ] Conteo de veh√≠culos que cruzan l√≠nea virtual
- [ ] Clasificaci√≥n de veh√≠culos por tipo (auto/moto/bus)
- [ ] Detecci√≥n de infracciones (sem√°foro en rojo)
- [ ] Streaming en tiempo real (c√°maras IP)

---

## üìû Soporte

Para problemas o preguntas sobre este m√≥dulo:

1. Ver documentaci√≥n en `datos/videos-prueba/README.md`
2. Ver entrenamiento de emergencias en `datos/entrenamiento-emergencia/README.md`
3. Revisar ejemplos en los archivos `test_*.py`

---

## üéâ Resumen

Este m√≥dulo es **100% REAL**:

‚úÖ **Velocidad**: Calculada con tracking real (DeepSORT/Centroid)
‚úÖ **ICV**: Calculado con `nucleo/indice_congestion.py` (mismo que MATLAB)
‚úÖ **Emergencias**: Modelo YOLO custom (cuando est√° entrenado)
‚úÖ **Flujo**: Basado en conteo de veh√≠culos trackeados
‚ùå **NO USA `np.random`** en ninguna parte

Todos los valores exportados en CSVs son verificables y reproducibles.
